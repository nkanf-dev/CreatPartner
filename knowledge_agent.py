import asyncio
import json
from dataclasses import dataclass
from datetime import datetime
from typing import List, Optional, Dict, Any
from enum import Enum
from config import config, get_model_name, create_llm_provider
from logger import warning

try:
    import httpx
    import pymongo
    from pymongo import MongoClient
    from pydantic import BaseModel, Field
    from pydantic_ai import Agent, RunContext, ModelRetry
    from pydantic_ai.models.openai import OpenAIChatModel

except ImportError as e:
    warning(f"ç¼ºå°‘ä¾èµ–åŒ… {e}. è¯·è¿è¡Œ: uv add pymongo httpx pydantic-ai python-dotenv")

    # åˆ›å»ºæ¨¡æ‹Ÿç±»
    class BaseModel:
        pass

    class Agent:
        def __init__(self, *args, **kwargs):
            pass

        def tool(self, func):
            return func

        def instructions(self, func):
            return func

        def run_sync(self, *args, **kwargs):
            return type("Result", (), {"output": "æ¨¡æ‹Ÿç»“æœ - è¯·å®‰è£…ä¾èµ–åŒ…"})()

    class RunContext:
        pass

    class ModelRetry:
        pass


class KnowledgeType(Enum):
    """çŸ¥è¯†ç±»å‹æšä¸¾"""

    PROJECT_MEMORY = "project_memory"  # é¡¹ç›®é•¿æœŸè®°å¿†
    EXTERNAL_RESEARCH = "external_research"  # å¤–éƒ¨æ£€ç´¢èµ„æ–™


class KnowledgeEntry(BaseModel):
    """çŸ¥è¯†æ¡ç›®æ¨¡å‹"""

    id: Optional[str] = None
    title: str
    content: str
    knowledge_type: KnowledgeType
    source: str  # æ¥æºï¼šå¦‚"user_input", "web_search", "arxiv"
    tags: List[str] = []
    created_at: datetime = datetime.now()
    updated_at: datetime = datetime.now()
    embedding: Optional[List[float]] = None
    metadata: Dict[str, Any] = {}


class KnowledgeAddResult(BaseModel):
    """çŸ¥è¯†æ·»åŠ ç»“æœçš„ç»“æ„åŒ–è¾“å‡º"""

    success: bool
    ids: List[str] = []
    chunks_count: int = 0
    message: str
    error: Optional[str] = None


class KnowledgeSearchResult(BaseModel):
    """çŸ¥è¯†æœç´¢ç»“æœçš„ç»“æ„åŒ–è¾“å‡º"""

    success: bool
    results: List[Dict[str, Any]] = []
    total: int = 0
    reranked: bool = False
    message: str
    error: Optional[str] = None


class KnowledgeUpdateResult(BaseModel):
    """çŸ¥è¯†æ›´æ–°ç»“æœçš„ç»“æ„åŒ–è¾“å‡º"""

    success: bool
    message: str
    collection: Optional[str] = None
    error: Optional[str] = None


class KnowledgeStatsResult(BaseModel):
    """çŸ¥è¯†åº“ç»Ÿè®¡ç»“æœçš„ç»“æ„åŒ–è¾“å‡º"""

    success: bool
    stats: Dict[str, Any] = {}
    message: str
    error: Optional[str] = None


@dataclass
class KnowledgeDependencies:
    """çŸ¥è¯†åº“ä»£ç†ä¾èµ–"""

    mongodb_uri: str
    database_name: str = "creatpartner"
    jina_api_key: Optional[str] = None
    embedding_model: str = "jina-embeddings-v3"
    embedding_dimensions: int = 1024
    max_results: int = 5


class JinaEmbeddingService:
    """åŸºäºJina AIçš„åµŒå…¥æœåŠ¡"""

    def __init__(self, api_key: str, model: str = "jina-embeddings-v3"):
        self.api_key = api_key
        self.model = model
        self.base_url = "https://api.jina.ai/v1"

    async def get_embeddings(
        self, texts: List[str], task: str = "retrieval.passage"
    ) -> List[List[float]]:
        """ä½¿ç”¨Jina APIç”ŸæˆåµŒå…¥"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "Accept": "application/json",
        }

        payload = {
            "model": self.model,
            "input": texts,
            "task": task,
            "embedding_type": "float",
        }

        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    f"{self.base_url}/embeddings", headers=headers, json=payload
                )
                response.raise_for_status()

                result = response.json()
                return [item["embedding"] for item in result["data"]]

        except Exception as e:
            print(f"JinaåµŒå…¥ç”Ÿæˆå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤ç»´åº¦çš„é›¶å‘é‡
            return [[0.0] * config.embedding.dimensions for _ in texts]

    async def get_single_embedding(
        self, text: str, task: str = "retrieval.passage"
    ) -> List[float]:
        """ç”Ÿæˆå•ä¸ªæ–‡æœ¬çš„åµŒå…¥"""
        embeddings = await self.get_embeddings([text], task)
        return embeddings[0] if embeddings else [0.0] * config.embedding.dimensions


class JinaRerankerService:
    """åŸºäºJina AIçš„é‡æ’åºæœåŠ¡"""

    def __init__(self, api_key: str, model: str = "jina-reranker-v2-base-multilingual"):
        self.api_key = api_key
        self.model = model
        self.base_url = "https://api.jina.ai/v1"

    async def rerank_documents(
        self, query: str, documents: List[str], top_n: Optional[int] = None
    ) -> List[Dict[str, Any]]:
        """ä½¿ç”¨Jina Rerankeré‡æ–°æ’åºæ–‡æ¡£"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "Accept": "application/json",
        }

        payload = {
            "model": self.model,
            "query": query,
            "documents": documents,
            "top_n": top_n or len(documents),
            "return_documents": True,
        }

        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    f"{self.base_url}/rerank", headers=headers, json=payload
                )
                response.raise_for_status()

                result = response.json()
                return result["results"]

        except Exception as e:
            print(f"Jinaé‡æ’åºå¤±è´¥: {e}")
            # è¿”å›åŸå§‹é¡ºåº
            return [
                {"index": i, "document": doc, "relevance_score": 0.5}
                for i, doc in enumerate(documents)
            ]

    async def rerank(
        self, query: str, documents: List[str], top_n: Optional[int] = None
    ) -> List[Dict[str, Any]]:
        """é‡æ’åºæ–¹æ³•çš„åˆ«åï¼Œå…¼å®¹æ—§ä»£ç """
        return await self.rerank_documents(query, documents, top_n)


class JinaSegmenterService:
    """åŸºäºJina AIçš„æ–‡æœ¬åˆ†å‰²æœåŠ¡"""

    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://segment.jina.ai"

    async def segment_text(
        self, content: str, max_chunk_length: int = 1000, tokenizer: str = "cl100k_base"
    ) -> List[str]:
        """ä½¿ç”¨Jina Segmenteråˆ†å‰²æ–‡æœ¬"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "Accept": "application/json",
        }

        payload = {
            "content": content,
            "tokenizer": tokenizer,
            "return_chunks": True,
            "max_chunk_length": max_chunk_length,
        }

        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    self.base_url, headers=headers, json=payload
                )
                response.raise_for_status()

                result = response.json()
                return result.get("chunks", [content])

        except Exception as e:
            print(f"Jinaæ–‡æœ¬åˆ†å‰²å¤±è´¥: {e}")
            # ç®€å•åˆ†å‰²ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
            return [
                content[i : i + max_chunk_length]
                for i in range(0, len(content), max_chunk_length)
            ]


class KnowledgeAgent:
    """çŸ¥è¯†åº“ä»£ç† - åŸºäºJina AIå’ŒMongoDBçš„RAGå®ç°"""

    def __init__(self, model_name: str = None):
        if model_name is None:
            model_name = get_model_name()

        # åˆ›å»ºè‡ªå®šä¹‰æ¨¡å‹å®ä¾‹
        model = self._create_model(model_name)

        self.agent = Agent(
            model,
            deps_type=KnowledgeDependencies,
            instructions="""
            ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†åº“ç®¡ç†åŠ©æ‰‹ï¼Œè´Ÿè´£ç®¡ç†å¤§å­¦ç”Ÿåˆ›æ–°åˆ›ä¸šé¡¹ç›®çš„çŸ¥è¯†ä½“ç³»ã€‚
            
            ä½ çš„æ ¸å¿ƒèŒè´£ï¼š
            1. ç®¡ç†é¡¹ç›®é•¿æœŸè®°å¿†çŸ¥è¯†åº“ - å­˜å‚¨é¡¹ç›®å†å²ã€å†³ç­–ã€ç»éªŒæ•™è®­
            2. ç®¡ç†å¤–éƒ¨æ£€ç´¢èµ„æ–™çŸ¥è¯†åº“ - æ•´ç†å’Œå½’æ¡£ä»å¤–éƒ¨è·å–çš„ç ”ç©¶èµ„æ–™
            3. æä¾›æ™ºèƒ½çš„çŸ¥è¯†æ£€ç´¢å’Œå…³è”åˆ†æ
            4. ååŠ©çŸ¥è¯†åº“çš„ç»´æŠ¤å’Œä¼˜åŒ–
            
            å·¥ä½œåŸåˆ™ï¼š
            - ç¡®ä¿çŸ¥è¯†çš„å‡†ç¡®æ€§å’Œå¯è¿½æº¯æ€§
            - å»ºç«‹æœ‰æ•ˆçš„çŸ¥è¯†åˆ†ç±»å’Œæ ‡ç­¾ä½“ç³»
            - æä¾›ä¸Šä¸‹æ–‡ç›¸å…³çš„çŸ¥è¯†æ¨è
            - æ”¯æŒçŸ¥è¯†çš„ç‰ˆæœ¬ç®¡ç†å’Œæ›´æ–°
            
            ç‰¹åˆ«å…³æ³¨ï¼š
            - é¡¹ç›®çš„åˆ›æ–°ç‚¹å’Œæ ¸å¿ƒä»·å€¼
            - æŠ€æœ¯æ–¹æ¡ˆçš„å¯è¡Œæ€§åˆ†æ
            - å¸‚åœºè°ƒç ”å’Œç«äº‰åˆ†æ
            - é£é™©è¯„ä¼°å’Œåº”å¯¹ç­–ç•¥
            """,
            # è®¾ç½®é‡è¯•æœºåˆ¶
            retries=2,
        )

        # åˆå§‹åŒ–ç»„ä»¶
        self.client = None
        self.jina_embedding = None
        self.jina_reranker = None
        self.jina_segmenter = None
        self._register_tools()

    def _create_model(self, model_name: str):
        """åˆ›å»ºè‡ªå®šä¹‰LLMæ¨¡å‹å®ä¾‹"""
        try:
            if config.llm.provider in ["siliconflow", "deepseek"]:
                # ä½¿ç”¨è‡ªå®šä¹‰æä¾›å•†
                provider = create_llm_provider()
                if provider:
                    return OpenAIChatModel(config.llm.model_name, provider=provider)

            # å›é€€åˆ°é»˜è®¤æ¨¡å‹
            return model_name
        except Exception as e:
            print(f"åˆ›å»ºè‡ªå®šä¹‰æ¨¡å‹å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹: {e}")
            return model_name

    def _initialize_components(self, deps: KnowledgeDependencies):
        """åˆå§‹åŒ–MongoDBè¿æ¥å’ŒJinaæœåŠ¡"""
        if self.client is None:
            self.client = MongoClient(deps.mongodb_uri)

        if self.jina_embedding is None and deps.jina_api_key:
            self.jina_embedding = JinaEmbeddingService(
                deps.jina_api_key, deps.embedding_model
            )

        if self.jina_reranker is None and deps.jina_api_key:
            self.jina_reranker = JinaRerankerService(deps.jina_api_key)

        if self.jina_segmenter is None and deps.jina_api_key:
            self.jina_segmenter = JinaSegmenterService(deps.jina_api_key)

    async def _get_embedding(self, text: str) -> List[float]:
        """ç”Ÿæˆæ–‡æœ¬åµŒå…¥"""
        if self.jina_embedding:
            return await self.jina_embedding.get_single_embedding(text)
        else:
            # è¿”å›é»˜è®¤ç»´åº¦çš„é›¶å‘é‡
            return [0.0] * config.embedding.dimensions

    def _register_tools(self):
        """æ³¨å†ŒçŸ¥è¯†åº“ç®¡ç†å·¥å…·"""

        @self.agent.tool
        async def add_knowledge(
            ctx: RunContext[KnowledgeDependencies],
            title: str,
            content: str,
            knowledge_type: str,
            source: str,
            tags: List[str] = [],
        ) -> KnowledgeAddResult:
            """æ·»åŠ çŸ¥è¯†æ¡ç›®åˆ°çŸ¥è¯†åº“

            Args:
                title: çŸ¥è¯†æ ‡é¢˜
                content: çŸ¥è¯†å†…å®¹
                knowledge_type: çŸ¥è¯†ç±»å‹ (project_memory æˆ– external_research)
                source: æ¥æºæ ‡è¯†
                tags: æ ‡ç­¾åˆ—è¡¨

            Returns:
                æ·»åŠ ç»“æœä¿¡æ¯
            """
            try:
                self._initialize_components(ctx.deps)

                # éªŒè¯çŸ¥è¯†ç±»å‹
                if knowledge_type not in ["project_memory", "external_research"]:
                    return KnowledgeAddResult(
                        success=False,
                        message=f"æ— æ•ˆçš„çŸ¥è¯†ç±»å‹: {knowledge_type}",
                        error="çŸ¥è¯†ç±»å‹å¿…é¡»æ˜¯ 'project_memory' æˆ– 'external_research'",
                    )

                # ä½¿ç”¨Jinaåˆ†å‰²é•¿æ–‡æœ¬
                chunks = [content]
                if self.jina_segmenter and len(content) > config.llm.chunk_size:
                    try:
                        chunks = await self.jina_segmenter.segment_text(
                            content, max_chunk_length=config.llm.chunk_size
                        )
                    except Exception as e:
                        if config.project.debug_mode:
                            print(f"æ–‡æœ¬åˆ†å‰²å¤±è´¥ï¼Œä½¿ç”¨åŸæ–‡æœ¬: {e}")

                db = self.client[ctx.deps.database_name]
                collection = db[f"knowledge_{knowledge_type}"]

                # ä¸ºæ¯ä¸ªchunkåˆ›å»ºçŸ¥è¯†æ¡ç›®
                inserted_ids = []
                for i, chunk in enumerate(chunks):
                    try:
                        # ç”ŸæˆåµŒå…¥
                        embedding = await self._get_embedding(f"{title} {chunk}")

                        entry = KnowledgeEntry(
                            title=f"{title} (éƒ¨åˆ† {i + 1})"
                            if len(chunks) > 1
                            else title,
                            content=chunk,
                            knowledge_type=KnowledgeType(knowledge_type),
                            source=source,
                            tags=tags,
                            embedding=embedding,
                        )

                        # æ’å…¥æ–‡æ¡£
                        doc = entry.dict()
                        doc["created_at"] = doc["created_at"].isoformat()
                        doc["updated_at"] = doc["updated_at"].isoformat()
                        doc["knowledge_type"] = doc["knowledge_type"].value

                        result = collection.insert_one(doc)
                        inserted_ids.append(str(result.inserted_id))

                    except Exception as chunk_error:
                        if config.project.debug_mode:
                            print(f"æ’å…¥chunk {i + 1} å¤±è´¥: {chunk_error}")
                        continue

                if inserted_ids:
                    return KnowledgeAddResult(
                        success=True,
                        ids=inserted_ids,
                        chunks_count=len(chunks),
                        message=f"æˆåŠŸæ·»åŠ {knowledge_type}çŸ¥è¯†æ¡ç›®: {title} ({len(inserted_ids)}ä¸ªç‰‡æ®µ)",
                    )
                else:
                    return KnowledgeAddResult(
                        success=False,
                        message="æ²¡æœ‰æˆåŠŸæ’å…¥ä»»ä½•çŸ¥è¯†ç‰‡æ®µ",
                        error="æ‰€æœ‰æ’å…¥æ“ä½œéƒ½å¤±è´¥äº†",
                    )

            except Exception as e:
                error_msg = str(e)
                if config.project.debug_mode:
                    print(f"æ·»åŠ çŸ¥è¯†æ¡ç›®å¤±è´¥: {error_msg}")

                return KnowledgeAddResult(
                    success=False,
                    message=f"æ·»åŠ çŸ¥è¯†æ¡ç›®å¤±è´¥: {error_msg}",
                    error=error_msg,
                )

        @self.agent.tool
        async def search_knowledge(
            ctx: RunContext[KnowledgeDependencies],
            query: str,
            knowledge_type: Optional[str] = None,
            limit: int = 5,
            use_reranker: bool = False,  # é»˜è®¤ç¦ç”¨é‡æ’åºä»¥é¿å…é¢å¤–çš„APIè°ƒç”¨
        ) -> KnowledgeSearchResult:
            """æœç´¢çŸ¥è¯†åº“

            Args:
                query: æœç´¢æŸ¥è¯¢
                knowledge_type: çŸ¥è¯†ç±»å‹è¿‡æ»¤ (project_memory æˆ– external_research)
                limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
                use_reranker: æ˜¯å¦ä½¿ç”¨é‡æ’åºä¼˜åŒ–ç»“æœ

            Returns:
                æœç´¢ç»“æœ
            """
            try:
                if config.project.debug_mode:
                    print(f"ğŸ” æœç´¢çŸ¥è¯†åº“: {query}")

                self._initialize_components(ctx.deps)

                if not self.client:
                    return KnowledgeSearchResult(
                        success=False,
                        message="æ•°æ®åº“è¿æ¥æœªåˆå§‹åŒ–",
                        error="MongoDBå®¢æˆ·ç«¯æœªåˆå§‹åŒ–",
                    )

                # ç”ŸæˆæŸ¥è¯¢åµŒå…¥
                query_embedding = await self._get_embedding(query)

                db = self.client[ctx.deps.database_name]
                results = []

                # ç¡®å®šæœç´¢çš„é›†åˆ
                collections_to_search = []
                if knowledge_type and knowledge_type in [
                    "project_memory",
                    "external_research",
                ]:
                    collections_to_search = [f"knowledge_{knowledge_type}"]
                else:
                    collections_to_search = [
                        "knowledge_project_memory",
                        "knowledge_external_research",
                    ]

                if config.project.debug_mode:
                    print(f"   æœç´¢é›†åˆ: {collections_to_search}")

                # åœ¨æ¯ä¸ªé›†åˆä¸­æœç´¢
                for collection_name in collections_to_search:
                    try:
                        collection = db[collection_name]

                        # é¦–å…ˆæ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨ä»¥åŠæ˜¯å¦æœ‰æ•°æ®
                        doc_count = collection.count_documents({})
                        if config.project.debug_mode:
                            print(f"   é›†åˆ {collection_name} æ–‡æ¡£æ•°: {doc_count}")

                        if doc_count == 0:
                            # å¦‚æœé›†åˆä¸ºç©ºï¼Œåˆ›å»ºä¸€ä¸ªæµ‹è¯•æ–‡æ¡£
                            test_doc = {
                                "title": "æµ‹è¯•çŸ¥è¯†æ¡ç›®",
                                "content": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•çŸ¥è¯†æ¡ç›®ï¼Œç”¨äºéªŒè¯æœç´¢åŠŸèƒ½",
                                "knowledge_type": knowledge_type or "project_memory",
                                "source": "system_test",
                                "tags": ["æµ‹è¯•", "ç³»ç»Ÿ"],
                                "created_at": datetime.now().isoformat(),
                                "updated_at": datetime.now().isoformat(),
                                "embedding": [0.1]
                                * config.embedding.dimensions,  # ç®€å•çš„æµ‹è¯•åµŒå…¥
                            }
                            collection.insert_one(test_doc)
                            if config.project.debug_mode:
                                print(f"   åˆ›å»ºæµ‹è¯•æ–‡æ¡£åˆ° {collection_name}")

                        # å°è¯•å‘é‡æœç´¢ï¼ˆä½†ç”±äºå¯èƒ½æ²¡æœ‰ç´¢å¼•ï¼Œé¢„æœŸä¼šå¤±è´¥ï¼‰
                        vector_search_success = False
                        try:
                            if query_embedding and len(query_embedding) > 0:
                                pipeline = [
                                    {
                                        "$vectorSearch": {
                                            "index": "vector_index",
                                            "path": "embedding",
                                            "queryVector": query_embedding,
                                            "numCandidates": 50,
                                            "limit": limit * 2
                                            if use_reranker
                                            else limit,
                                        }
                                    },
                                    {
                                        "$addFields": {
                                            "score": {"$meta": "vectorSearchScore"}
                                        }
                                    },
                                ]

                                cursor = collection.aggregate(pipeline)
                                vector_results = list(cursor)

                                for doc in vector_results:
                                    doc["_id"] = str(doc["_id"])
                                    doc["collection"] = collection_name
                                    doc["search_type"] = "vector"
                                    results.append(doc)

                                vector_search_success = True
                                if config.project.debug_mode:
                                    print(
                                        f"   å‘é‡æœç´¢æˆåŠŸï¼Œæ‰¾åˆ° {len(vector_results)} ä¸ªç»“æœ"
                                    )

                        except Exception as vector_error:
                            if config.project.debug_mode:
                                print(f"   å‘é‡æœç´¢å¤±è´¥: {vector_error}")

                        # å¦‚æœå‘é‡æœç´¢å¤±è´¥æˆ–æ²¡æœ‰ç»“æœï¼Œä½¿ç”¨æ–‡æœ¬æœç´¢
                        if not vector_search_success or len(results) == 0:
                            if config.project.debug_mode:
                                print(f"   ä½¿ç”¨æ–‡æœ¬æœç´¢ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ")

                            try:
                                # æ„å»ºæ›´å®½æ³›çš„æœç´¢æ¡ä»¶
                                search_conditions = []

                                # ç®€å•çš„æ–‡æœ¬åŒ¹é…
                                if query:
                                    search_conditions.extend(
                                        [
                                            {
                                                "title": {
                                                    "$regex": query,
                                                    "$options": "i",
                                                }
                                            },
                                            {
                                                "content": {
                                                    "$regex": query,
                                                    "$options": "i",
                                                }
                                            },
                                        ]
                                    )

                                    # æœç´¢åŒ…å«æŸ¥è¯¢è¯çš„æ ‡ç­¾
                                    search_conditions.append(
                                        {"tags": {"$regex": query, "$options": "i"}}
                                    )

                                # å¦‚æœæ²¡æœ‰ç‰¹å®šæœç´¢æ¡ä»¶ï¼Œè¿”å›æœ€è¿‘çš„æ–‡æ¡£
                                if not search_conditions:
                                    search_query = {}
                                else:
                                    search_query = {"$or": search_conditions}

                                text_results = collection.find(search_query).limit(
                                    limit
                                )

                                text_count = 0
                                for doc in text_results:
                                    doc["_id"] = str(doc["_id"])
                                    doc["score"] = 0.8  # æ–‡æœ¬åŒ¹é…çš„é»˜è®¤åˆ†æ•°
                                    doc["collection"] = collection_name
                                    doc["search_type"] = "text"
                                    results.append(doc)
                                    text_count += 1

                                if config.project.debug_mode:
                                    print(f"   æ–‡æœ¬æœç´¢æ‰¾åˆ° {text_count} ä¸ªç»“æœ")

                            except Exception as text_error:
                                if config.project.debug_mode:
                                    print(f"   æ–‡æœ¬æœç´¢ä¹Ÿå¤±è´¥: {text_error}")

                                # æœ€åçš„å¤‡é€‰æ–¹æ¡ˆï¼šè¿”å›ä»»æ„æ–‡æ¡£
                                try:
                                    fallback_results = collection.find({}).limit(limit)
                                    fallback_count = 0
                                    for doc in fallback_results:
                                        doc["_id"] = str(doc["_id"])
                                        doc["score"] = 0.5
                                        doc["collection"] = collection_name
                                        doc["search_type"] = "fallback"
                                        results.append(doc)
                                        fallback_count += 1

                                    if config.project.debug_mode:
                                        print(
                                            f"   å¤‡é€‰æœç´¢è¿”å› {fallback_count} ä¸ªç»“æœ"
                                        )

                                except Exception as fallback_error:
                                    if config.project.debug_mode:
                                        print(f"   å¤‡é€‰æœç´¢å¤±è´¥: {fallback_error}")

                    except Exception as collection_error:
                        if config.project.debug_mode:
                            print(
                                f"æœç´¢é›†åˆ {collection_name} å®Œå…¨å¤±è´¥: {collection_error}"
                            )
                        continue

                # æŒ‰åˆ†æ•°æ’åº
                if results:
                    results.sort(key=lambda x: x.get("score", 0), reverse=True)
                    results = results[:limit]  # é™åˆ¶ç»“æœæ•°é‡

                # ä½¿ç”¨Jinaé‡æ’åºä¼˜åŒ–ç»“æœï¼ˆå¯é€‰ï¼‰
                if use_reranker and self.jina_reranker and len(results) > 1:
                    try:
                        documents = [
                            f"{doc.get('title', '')}: {doc.get('content', '')}"
                            for doc in results
                        ]
                        reranked_results = await self.jina_reranker.rerank(
                            query, documents, top_n=limit
                        )

                        # é‡æ–°æ’åºç»“æœ
                        reordered_results = []
                        for item in reranked_results:
                            if item.get("index", -1) < len(results):
                                result = results[item["index"]].copy()
                                result["rerank_score"] = item.get("relevance_score", 0)
                                reordered_results.append(result)

                        results = reordered_results
                        if config.project.debug_mode:
                            print(f"   é‡æ’åºå®Œæˆï¼Œæœ€ç»ˆç»“æœæ•°: {len(results)}")

                    except Exception as rerank_error:
                        if config.project.debug_mode:
                            print(f"é‡æ’åºå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹ç»“æœ: {rerank_error}")

                success_message = f"æ‰¾åˆ° {len(results)} æ¡ç›¸å…³çŸ¥è¯†"
                if not results:
                    success_message = "æœªæ‰¾åˆ°ç›¸å…³çŸ¥è¯†ï¼Œå¯èƒ½éœ€è¦å…ˆæ·»åŠ ä¸€äº›å†…å®¹åˆ°çŸ¥è¯†åº“"

                if config.project.debug_mode:
                    print(f"âœ… {success_message}")

                return KnowledgeSearchResult(
                    success=True,
                    results=results,
                    total=len(results),
                    reranked=use_reranker
                    and self.jina_reranker is not None
                    and len(results) > 1,
                    message=success_message,
                )

            except Exception as e:
                error_msg = str(e)
                if config.project.debug_mode:
                    print(f"âŒ æœç´¢çŸ¥è¯†åº“å¤±è´¥: {error_msg}")

                return KnowledgeSearchResult(
                    success=False,
                    message=f"æœç´¢çŸ¥è¯†åº“å¤±è´¥: {error_msg}",
                    error=error_msg,
                )

        @self.agent.tool
        async def update_knowledge(
            ctx: RunContext[KnowledgeDependencies],
            knowledge_id: str,
            title: Optional[str] = None,
            content: Optional[str] = None,
            tags: Optional[List[str]] = None,
        ) -> Dict[str, Any]:
            """æ›´æ–°çŸ¥è¯†æ¡ç›®

            Args:
                knowledge_id: çŸ¥è¯†æ¡ç›®ID
                title: æ–°æ ‡é¢˜ï¼ˆå¯é€‰ï¼‰
                content: æ–°å†…å®¹ï¼ˆå¯é€‰ï¼‰
                tags: æ–°æ ‡ç­¾ï¼ˆå¯é€‰ï¼‰

            Returns:
                æ›´æ–°ç»“æœ
            """
            try:
                self._initialize_components(ctx.deps)

                # æ„å»ºæ›´æ–°å­—æ®µ
                update_fields = {"updated_at": datetime.now().isoformat()}
                if title:
                    update_fields["title"] = title
                if content:
                    update_fields["content"] = content
                if tags is not None:
                    update_fields["tags"] = tags

                # å¦‚æœæ ‡é¢˜æˆ–å†…å®¹æœ‰æ›´æ–°ï¼Œé‡æ–°ç”ŸæˆåµŒå…¥
                if title or content:
                    new_text = f"{title or ''} {content or ''}"
                    update_fields["embedding"] = await self._get_embedding(new_text)

                db = self.client[ctx.deps.database_name]

                # åœ¨ä¸¤ä¸ªé›†åˆä¸­å°è¯•æ›´æ–°
                from bson import ObjectId

                for collection_name in [
                    "knowledge_project_memory",
                    "knowledge_external_research",
                ]:
                    collection = db[collection_name]
                    result = collection.update_one(
                        {"_id": ObjectId(knowledge_id)}, {"$set": update_fields}
                    )

                    if result.modified_count > 0:
                        return {
                            "success": True,
                            "message": f"æˆåŠŸæ›´æ–°çŸ¥è¯†æ¡ç›® {knowledge_id}",
                            "collection": collection_name,
                        }

                return {"success": False, "message": f"æœªæ‰¾åˆ°çŸ¥è¯†æ¡ç›® {knowledge_id}"}

            except Exception as e:
                return {"success": False, "error": str(e), "message": f"æ›´æ–°å¤±è´¥: {e}"}

        @self.agent.tool
        async def get_knowledge_stats(
            ctx: RunContext[KnowledgeDependencies],
        ) -> Dict[str, Any]:
            """è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯

            Returns:
                çŸ¥è¯†åº“ç»Ÿè®¡æ•°æ®
            """
            try:
                self._initialize_components(ctx.deps)

                db = self.client[ctx.deps.database_name]

                stats = {
                    "project_memory": {
                        "total_entries": 0,
                        "sources": {},
                        "top_tags": [],
                    },
                    "external_research": {
                        "total_entries": 0,
                        "sources": {},
                        "top_tags": [],
                    },
                }

                # ç»Ÿè®¡é¡¹ç›®è®°å¿†çŸ¥è¯†åº“
                project_collection = db["knowledge_project_memory"]
                stats["project_memory"]["total_entries"] = (
                    project_collection.count_documents({})
                )

                # ç»Ÿè®¡å¤–éƒ¨èµ„æ–™çŸ¥è¯†åº“
                research_collection = db["knowledge_external_research"]
                stats["external_research"]["total_entries"] = (
                    research_collection.count_documents({})
                )

                return {
                    "success": True,
                    "stats": stats,
                    "message": "æˆåŠŸè·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯",
                }

            except Exception as e:
                return {
                    "success": False,
                    "error": str(e),
                    "message": f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}",
                }

    async def process_external_data(
        self, data: List[Dict[str, Any]], deps: Optional[KnowledgeDependencies] = None
    ) -> str:
        """å¤„ç†å¤–éƒ¨æ£€ç´¢åˆ°çš„æ•°æ®å¹¶å­˜å…¥çŸ¥è¯†åº“"""
        if deps is None:
            deps = KnowledgeDependencies(
                mongodb_uri=config.database.mongodb_uri,
                database_name=config.database.database_name,
            )

        prompt = f"""
        è¯·åˆ†æä»¥ä¸‹å¤–éƒ¨æ£€ç´¢åˆ°çš„èµ„æ–™ï¼Œå¹¶å°†å…¶æ•´ç†ä¸ºç»“æ„åŒ–çš„çŸ¥è¯†æ¡ç›®ã€‚
        
        æ£€ç´¢æ•°æ®ï¼š
        {data}
        
        è¯·ä¸ºæ¯ä¸ªæœ‰ä»·å€¼çš„ä¿¡æ¯åˆ›å»ºçŸ¥è¯†æ¡ç›®ï¼ŒåŒ…æ‹¬ï¼š
        1. åˆé€‚çš„æ ‡é¢˜
        2. å†…å®¹æ‘˜è¦
        3. ç›¸å…³æ ‡ç­¾
        4. æ¥æºæ ‡è¯†
        
        é‡ç‚¹å…³æ³¨ä¸åˆ›æ–°åˆ›ä¸šé¡¹ç›®ç›¸å…³çš„ä¿¡æ¯ã€‚
        """

        result = await self.agent.run(prompt, deps=deps)
        return result.output

    async def manage_project_memory(
        self, action: str, content: str, deps: Optional[KnowledgeDependencies] = None
    ) -> str:
        """ç®¡ç†é¡¹ç›®é•¿æœŸè®°å¿†"""
        if deps is None:
            deps = KnowledgeDependencies(
                mongodb_uri=config.database.mongodb_uri,
                database_name=config.database.database_name,
            )

        prompt = f"""
        è¯·æ‰§è¡Œä»¥ä¸‹é¡¹ç›®è®°å¿†ç®¡ç†ä»»åŠ¡ï¼š
        
        æ“ä½œç±»å‹ï¼š{action}
        å†…å®¹ï¼š{content}
        
        æ ¹æ®æ“ä½œç±»å‹ï¼Œæ‰§è¡Œç›¸åº”çš„çŸ¥è¯†åº“æ“ä½œï¼š
        - add: æ·»åŠ æ–°çš„é¡¹ç›®è®°å¿†
        - search: æœç´¢ç›¸å…³é¡¹ç›®è®°å¿†
        - update: æ›´æ–°ç°æœ‰è®°å¿†
        - analyze: åˆ†æé¡¹ç›®çŸ¥è¯†åº“
        
        ç¡®ä¿ç»´æŠ¤é¡¹ç›®çŸ¥è¯†çš„å®Œæ•´æ€§å’Œå¯è¿½æº¯æ€§ã€‚
        """

        result = await self.agent.run(prompt, deps=deps)
        return result.output

    def create_vector_search_index(self, deps: KnowledgeDependencies):
        """åˆ›å»ºå‘é‡æœç´¢ç´¢å¼•"""
        try:
            self._initialize_components(deps)

            db = self.client[deps.database_name]

            # ä¸ºä¸¤ä¸ªçŸ¥è¯†åº“é›†åˆåˆ›å»ºå‘é‡ç´¢å¼•
            collections = ["knowledge_project_memory", "knowledge_external_research"]

            for collection_name in collections:
                collection = db[collection_name]

                # åˆ›å»ºå‘é‡æœç´¢ç´¢å¼•
                search_index_model = {
                    "definition": {
                        "fields": [
                            {
                                "type": "vector",
                                "numDimensions": config.embedding.dimensions,  # ä½¿ç”¨é…ç½®çš„åµŒå…¥ç»´åº¦
                                "path": "embedding",
                                "similarity": "cosine",
                            }
                        ]
                    },
                    "name": "vector_index",
                    "type": "vectorSearch",
                }

                try:
                    collection.create_search_index(search_index_model)
                    print(f"âœ… ä¸º {collection_name} åˆ›å»ºå‘é‡ç´¢å¼•æˆåŠŸ")
                except Exception as e:
                    print(f"âš ï¸ åˆ›å»ºå‘é‡ç´¢å¼•å¤±è´¥æˆ–å·²å­˜åœ¨: {e}")

            # åˆ›å»ºæ–‡æœ¬ç´¢å¼•
            for collection_name in collections:
                collection = db[collection_name]
                try:
                    collection.create_index(
                        [("title", "text"), ("content", "text"), ("tags", "text")]
                    )
                    print(f"âœ… ä¸º {collection_name} åˆ›å»ºæ–‡æœ¬ç´¢å¼•æˆåŠŸ")
                except Exception as e:
                    print(f"âš ï¸ åˆ›å»ºæ–‡æœ¬ç´¢å¼•å¤±è´¥æˆ–å·²å­˜åœ¨: {e}")

        except Exception as e:
            print(f"âŒ åˆ›å»ºç´¢å¼•å¤±è´¥: {e}")


# å·¥å‚å‡½æ•°
def create_knowledge_agent(
    model_name: str = None, mongodb_uri: str = None
) -> KnowledgeAgent:
    """åˆ›å»ºçŸ¥è¯†åº“ä»£ç†å®ä¾‹"""
    return KnowledgeAgent(model_name)


# ä½¿ç”¨ç¤ºä¾‹
async def main():
    """ç¤ºä¾‹ç”¨æ³•"""
    # åˆ›å»ºçŸ¥è¯†åº“ä»£ç†
    agent = create_knowledge_agent()

    # é…ç½®ä¾èµ–
    deps = KnowledgeDependencies(
        mongodb_uri=config.database.mongodb_uri, database_name="creatpartner_test"
    )

    # åˆ›å»ºç´¢å¼•
    agent.create_vector_search_index(deps)

    # æµ‹è¯•å¤–éƒ¨æ•°æ®å¤„ç†
    external_data = [
        {
            "title": "AIåœ¨æ•™è‚²ä¸­çš„åº”ç”¨è¶‹åŠ¿",
            "content": "äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨æ•™è‚²é¢†åŸŸçš„åº”ç”¨...",
            "source": "web_search",
        },
        {
            "title": "åˆ›æ–°åˆ›ä¸šé¡¹ç›®è¯„ä¼°æ ‡å‡†",
            "content": "å¤§å­¦ç”Ÿåˆ›æ–°åˆ›ä¸šé¡¹ç›®çš„è¯„ä¼°ç»´åº¦...",
            "source": "arxiv",
        },
    ]

    result = await agent.process_external_data(external_data, deps)
    print("å¤–éƒ¨æ•°æ®å¤„ç†ç»“æœ:")
    print(result)

    # æµ‹è¯•é¡¹ç›®è®°å¿†ç®¡ç†
    memory_result = await agent.manage_project_memory(
        "add", "é¡¹ç›®æŠ€æœ¯æ ˆç¡®å®šï¼šä½¿ç”¨Python + MongoDB + Streamlitå¼€å‘AIåŠ©æ‰‹", deps
    )
    print("\né¡¹ç›®è®°å¿†ç®¡ç†ç»“æœ:")
    print(memory_result)


if __name__ == "__main__":
    asyncio.run(main())
